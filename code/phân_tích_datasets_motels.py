# -*- coding: utf-8 -*-
"""Phân_tích_datasets_motels.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JPsyZhwokM9OMnU8wwnwZTtBe4a8Mn8b
"""

#import thư viện
from textblob import TextBlob
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction import text
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score
import seaborn as sns

df = pd.read_csv("datasets_motels.csv")
df.head(5)

df.isna().sum()

df.info()

#Phân bố nơi tọa lạc của các nhà trọ
import plotly.graph_objects as go
fig = go.Figure([go.Bar(x=df.toalac.value_counts().index, y=df.toalac.value_counts().tolist())])
fig.update_layout(
    title="Phân bố nơi tọa lạc của các nhà trọ",
    xaxis_title="Nơi tọa lạc",
    yaxis_title="Số lượng")
fig.show()

#Phân bố đánh giá của các nhà trọ
import plotly.graph_objects as go
fig = go.Figure([go.Bar(x=df.danhgia.value_counts().index, y=df.danhgia.value_counts().tolist())])
fig.update_layout(
    title="Phân bố đánh giá của các nhà trọ",
    xaxis_title="Đánh giá",
    yaxis_title="Số lượng")
fig.show()

#Phân bố diện tích của các nhà trọ
import plotly.graph_objects as go
fig = go.Figure([go.Bar(x=df.dientich.value_counts().index, y=df.dientich.value_counts().tolist())])
fig.update_layout(
    title="Phân bố diện tích của các nhà trọ",
    xaxis_title="Diện tích",
    yaxis_title="Số lượng")
fig.show()

def sentiment(gia):
  if gia in range(0,1000000):
    return 'Dưới 1 triệu'
  elif gia in range(1000001,2000000):
    return '1 triệu - 2 triệu'
  else:
    return 'Trên 2 triệu'

df['gia1'] = df['gia'].apply(sentiment)
df

#Phân bố giá của các nhà trọ
import plotly.graph_objects as go
fig = go.Figure([go.Bar(x=df.gia1.value_counts().index, y=df.gia1.value_counts().tolist())])
fig.update_layout(
    title="Phân bố giá của các nhà trọ",
    xaxis_title="Giá",
    yaxis_title="Số lượng")
fig.show()

#plt.figure(figsize=(25,20))
#sns.countplot(x= df['gia1'])

def sentiment(luotxem):
  if luotxem in range(0,1000):
    return 'Thấp'
  elif luotxem in range(1001,10000):
    return 'Trung Bình'
  elif luotxem in range(10001,50000):
    return 'Khá'
  elif luotxem in range(50001,70000):
    return 'Tốt'
  else:
    return 'Rất tốt'

df['luotxem1'] = df['luotxem'].apply(sentiment)
df.head()

#Phân bố lượt xem của các nhà trọ
import plotly.graph_objects as go
fig = go.Figure([go.Bar(x=df.luotxem1.value_counts().index, y=df.luotxem1.value_counts().tolist())])
fig.update_layout(
    title="Phân bố lượt xem của các nhà trọ",
    xaxis_title="Lượt xem",
    yaxis_title="Số lượng")
fig.show()

#plt.figure(figsize=(16,4))
#sns.countplot(x= df['luotxem1'])

df = pd.read_csv("datasets_reviews_motels.csv")
df.head(5)

sentiments = []
for review in df['views']:
    if TextBlob(review).sentiment.polarity < 0:
        sentiments.append("Negative")
    if TextBlob(review).sentiment.polarity == 0:
        sentiments.append("Neutral")
    if TextBlob(review).sentiment.polarity > 0:
        sentiments.append("Positive")
df["Sentiment"] = np.array(sentiments)

df

df['rating'].value_counts()

#Phân bố độ rating và giá trị tình cảm đánh giá
plt.figure(figsize=(15,5))
plt.subplot(1,2,1)
x_axis,counts = np.unique(df['rating'],return_counts=True)
plt.bar([str(i) for i in x_axis],counts)
plt.title("Phân bố rating")
plt.xlabel("Rating")
plt.ylabel("Count")

plt.subplot(1,2,2)
x_axis,counts = np.unique(df['Sentiment'],return_counts=True)
plt.bar(x_axis,counts)
plt.title("Phân bố Sentiment vs Counts")
plt.xlabel("Sentiment")
plt.ylabel("Count")
plt.tight_layout()

df['Word_count']= df['views'].map(lambda x: len(x.split()))
df

sns.lineplot(x='rating', data=df, y='Word_count')

from textblob import TextBlob

def polarity(text):
    blob= TextBlob(text)
    blob.sentiment
    polarity= blob.sentiment.polarity
    
    return polarity

def subjectivity(text):
    blob= TextBlob(text)
    blob.sentiment
    subjectivity= blob.sentiment.subjectivity
    
    return subjectivity

df['Polarity']= df['views'].apply(polarity)
df['Subjectivity']= df['views'].apply(subjectivity)
df

sns.distplot(df['Polarity'])

sns.distplot(df['Subjectivity'])

#Phân bố đánh giá ở lớp Polarity
import plotly.graph_objects as go
fig = go.Figure([go.Bar(x=df.rating.value_counts().index, y=df.Polarity.value_counts().tolist())])
fig.update_layout(
    title="Phân bố đánh giá ở lớp Polarity",
    xaxis_title="Đánh giá",
    yaxis_title="Số lượng")
fig.show()

#sns.boxplot(x='rating',y='Polarity', data=df, whis=2.5, fliersize= 5)

#Phân bố đánh giá ở lớp Subjectivity
import plotly.graph_objects as go
fig = go.Figure([go.Bar(x=df.rating.value_counts().index, y=df.Subjectivity.value_counts().tolist())])
fig.update_layout(
    title="Phân bố đánh giá ở lớp Subjectivity",
    xaxis_title="Đánh giá",
    yaxis_title="Số lượng")
fig.show()

#sns.boxplot(x='rating',y='Subjectivity', data=df, whis=2 )

# import matplotlib.pyplot as plt
# plt.plot(history.history['loss'], label='loss')
# plt.plot(history.history['val_loss'], label='val_loss')
# plt.legend()
# plt.show()
#plt.savefig("Loss plot.jpg")

import spacy
nlp= spacy.load('en_core_web_sm')

def preprocess(text):
    lower= text.lower()
    doc= nlp(lower)
    tokens= [token.lemma_ for token in doc ]
    a_lemma= [lemma for lemma in tokens if lemma not in spacy.lang.en.stop_words.STOP_WORDS and lemma.isalpha()]
    return " ".join(a_lemma)

df['Review_new']= df['views'].apply(preprocess)

df

rev= " ".join([review for review in df['Review_new']])
rev[:2000]

from wordcloud import WordCloud
plt.figure(figsize=(15,10))
wc= WordCloud(max_words=200,height= 800, width=1000 ,background_color='black').generate(rev)
plt.imshow(wc)

def sentiment(review):
    if review>=3:
        return '1'
    else:
        return '0'
df['Sentiment']= df['rating'].apply(sentiment)
df

#df.to_csv('2.csv',encoding="utf-8-sig",index=False)
#len(data)

#nationsGrp.groups

#subsetting dataset
#data=df[['id_motels','Sentiment']]
#data

#dt=data.query('id_motels=="16"')
#dt

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from nltk import word_tokenize

X= df['Review_new']
y= df['Sentiment']

X_train, X_test,y_train, y_test= train_test_split(X, y, test_size=0.3, stratify=y)

X_train

y_train

import nltk
nltk.download('punkt')

tfidf= TfidfVectorizer(max_features=10000, tokenizer= word_tokenize,ngram_range=(1,2) )
X_train_transformed= tfidf.fit_transform(X_train.values)
X_test_transformed= tfidf.transform(X_test.values)

X_train_transformed.shape

from sklearn.ensemble import RandomForestClassifier

rfc= RandomForestClassifier()
rfc.fit(X_train_transformed, y_train)
y_pred= rfc.predict(X_test_transformed)

rfc.score(X_test_transformed, y_test)

from sklearn.linear_model import LogisticRegression

lr= LogisticRegression()
lr.fit(X_train_transformed, y_train)
y_pred= lr.predict(X_test_transformed)

lr.score(X_test_transformed, y_test)

vectorizer = TfidfVectorizer(stop_words=text.ENGLISH_STOP_WORDS)
X_train,X_test,Y_train,Y_test = train_test_split(vectorizer.fit_transform(df['views']).toarray(),
                                                 df['Sentiment'].values,
                                                 test_size = 0.2,
                                                 random_state=42)

clf = LogisticRegression(solver='liblinear',random_state=0)
clf.fit(X_train,Y_train)
print("Train Accuracy : {:.2f} %".format(accuracy_score(clf.predict(X_train),Y_train)*100))
print("Test Accuracy  : {:.2f} %".format(accuracy_score(clf.predict(X_test),Y_test)*100))

for i in range (0,100):
  vectorizer = TfidfVectorizer(stop_words=text.ENGLISH_STOP_WORDS)
  X_train,X_test,Y_train,Y_test = train_test_split(vectorizer.fit_transform(df['views']).toarray(),
                                                 df['Sentiment'].values,
                                                 test_size = 0.3,
                                                 random_state=42 + i)
  
  clf = LogisticRegression(solver='liblinear',random_state= i)
  clf.fit(X_train,Y_train)
  
  rfc= RandomForestClassifier()
  rfc.fit(X_train,Y_train)
  print("Lân thứ ", i)
  print("Train Accuracy LogisticRegression : {:.2f} %".format(accuracy_score(clf.predict(X_train),Y_train)*100))
  print("Test Accuracy  LogisticRegression: {:.2f} %".format(accuracy_score(clf.predict(X_test),Y_test)*100))
  print("Train Accuracy RandomForestClassifier: {:.2f} %".format(accuracy_score(rfc.predict(X_train),Y_train)*100))
  print("Test Accuracy  RandomForestClassifier: {:.2f} %".format(accuracy_score(rfc.predict(X_test),Y_test)*100))
  print("\n")

# empty = []

# for i in df.itertuples():
#     if type(review) == str:
#         if review.isspace():
#             empty.append(i) # will take the index of that review
            
            
# print(f"There are total {len(empty)} empty strings as review.")

# Gán Id cho tất cả các từ duy nhất có trong cột views
from tensorflow.keras.preprocessing.text import Tokenizer

tokenizer = Tokenizer()

tokenizer.fit_on_texts(df['views'])

# Tổng số từ duy nhất có trong tất cả các bản tóm tắt được kết hợp
vocab_size = len(tokenizer.index_word)

# tokenizer.index word là một từ điển có thể được sử dụng để xem tất cả các từ duy nhất và có ID.

print(f'There are total {vocab_size} unique words present')

# Thay thế từng từ trong bài đánh giá bằng mã thông báo tương ứng
sequences = tokenizer.texts_to_sequences(df['views'])
tokenizer.index_word

# Tạo mô hình RNN-NLP, mỗi đầu vào phải có độ dài bằng nhau
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Giữ độ dài của đầu vào là 100. Vì vậy, nếu bất kỳ đầu vào nào có độ dài nhỏ hơn 100, các số 0 thừa sẽ được thêm vào
# Bất kỳ đầu vào nào có độ dài hơn 100 sẽ bị loại bỏ từ thừa.
sequences_padded = pad_sequences(sequences,maxlen=100,padding='post')
sequences_padded

df[['Sentiment']] = df[['Sentiment']].astype('int')
df['Sentiment'].unique()
y = np.array(df['Sentiment'])
y

# Các biến đầu vào và đầu ra. Chia dữ liệu thành tập hợp test và train
from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test = train_test_split(sequences_padded,y,test_size=0.3)

# Các thư viện để tạo và đào tạo mô hình
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Embedding

# Mô hình
max_len = 100 # độ dài của mỗi đầu vào
embedding_size = 32

model = Sequential()

model.add(Embedding(vocab_size+1,embedding_size,input_length = max_len))

model.add(LSTM(150,return_sequences=True))
model.add(Dropout(0.2))

model.add(LSTM(150))
model.add(Dropout(0.2))

model.add(Dense(256,activation='relu'))
model.add(Dropout(0.2))

model.add(Dense(128,activation='relu'))

model.add(Dense(1,activation='sigmoid'))

model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

model.summary()

# Train mô hình
model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=15,batch_size=64)

metrics = pd.DataFrame(model.history.history)

metrics

metrics[['loss','val_loss']].plot()
metrics[['accuracy','val_accuracy']].plot()

# ví dụ một reviews
neg_review = ['Nhà trọ hơi bì tù do nhiều phòng, giá hơi cao so với phòbg nhưng được cái nước ko ngập, ở 1 mình ok {tùy chổ, phòng mình 800k, có chổ 1 p 2tr3). Chủ trọ không có ở chung nên cũng thoải mái, đóng tiền trọ chễ ko bị la rầy như chổ khác.']

#mã hóa và thực hiện pad_sequence để làm đúng định dạng được chấp nhận bởi mô hình
neg_review_token = tokenizer.texts_to_sequences(neg_review)

# padding
neg_review_padded = pad_sequences(neg_review_token,maxlen=100,padding='post')

review_predict = (model.predict(neg_review_padded)>0.5).astype('int32')

# 1 là đánh giá tích cực và 0 là đánh giá tiêu cực
if review_predict[0] == 0:
    print("Đó là một đánh giá tiêu cực")
else:
    print("Đó là một đánh giá tích cực")

#Đánh giá tích cực
pos_review = ["Chủ trọ thân thiện dễ gần vui vẻ, trọ ở yên tĩnh. Phòng trọ rộng rãi thoáng mát, có nhiều camera, đặc biệt có chó giữ nhà rất giỏi."]

#Mã hóa
pos_review = tokenizer.texts_to_sequences(pos_review)

#padding
pos_review = pad_sequences(pos_review,maxlen=100,padding='post')

#dự đoán
review_predict = (model.predict(pos_review)>0.5).astype('int')

if review_predict[0] == 0:
    print("It's a negative review")
else:
    print("It's a positive review")

# Dự đoán trên X_test
prediction = (model.predict(X_test)>0.5).astype('int32')
# Đánh giá
from sklearn.metrics import classification_report
print(classification_report(y_test,prediction))